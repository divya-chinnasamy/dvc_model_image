{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import os\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 400 files [00:00, 761.85 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "input_folder = 'data/'\n",
    "splitfolders.ratio(input_folder, output=\"output_folder\", seed=42, ratio=(.7, .2, .1), group_prefix=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your folder containing images\n",
    "train_path=\"v_data/train\"\n",
    "test_path=\"v_data/test\"\n",
    "val_path=\"v_data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the image arrays\n",
    "x_train = []\n",
    "\n",
    "# Iterate over all image files in the folder\n",
    "for filename in os.listdir(train_path):\n",
    "    sub_path=train_path+\"/\"+ filename\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "        x_train.append(img_arr)\n",
    "\n",
    "# Convert the list of arrays into a NumPy array\n",
    "x_train_np = np.array(x_train)\n",
    "\n",
    "# Print the shape of the resulting array (should be something like (num_images, 256, 256, 3))\n",
    "print(\"Shape of the NumPy array:\", x_train_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "for folder in os.listdir(test_path):\n",
    "    sub_path=test_path+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "        x_test.append(img_arr)\n",
    "\n",
    "x_val=[]\n",
    "for folder in os.listdir(val_path):\n",
    "    sub_path=val_path+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "        x_val.append(img_arr)\n",
    "\n",
    "# Convert the list of arrays into a NumPy array\n",
    "x_test_np = np.array(x_test)\n",
    "x_val_np = np.array(x_val)\n",
    "# Print the shape of the resulting array (should be something like (num_images, 256, 256, 3))\n",
    "print(\"Shape of the NumPy array:\", x_test_np.shape)\n",
    "print(\"Shape of the NumPy array:\", x_val_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "train_x=x_train_np/255.0 \n",
    "test_x=x_test_np/255.0 \n",
    "val_x=x_val_np/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.legacy.preprocessing.image.ImageDataGenerator object at 0x000001AC80BDDB50>\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator for data augmentation and rescaling\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "print(train_datagen)\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "<keras.src.legacy.preprocessing.image.ImageDataGenerator object at 0x000001AC80BDDB50>\n",
      "<keras.src.legacy.preprocessing.image.DirectoryIterator object at 0x000001AC82338980>\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    class_mode='categorical'  \n",
    ")\n",
    "\n",
    "# Load and preprocess the validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(train_datagen)\n",
    "print(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divyaprabha\\.conda\\envs\\ml-pipeline\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Build a model\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(224, 224,3)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150528</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">19,267,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150528\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m19,267,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,267,970</span> (73.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,267,970\u001b[0m (73.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,267,970</span> (73.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,267,970\u001b[0m (73.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # Use 'binary_crossentropy' for binary classification\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 11:42:20 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ed40abfdd95146be91065b5f1152ec5e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2024/09/13 11:42:20 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2024/09/13 11:42:20 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divyaprabha\\.conda\\envs\\ml-pipeline\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 213ms/step - accuracy: 0.5333 - loss: 71.7351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Divyaprabha\\.conda\\envs\\ml-pipeline\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4835 - loss: 65.0152 - val_accuracy: 0.6000 - val_loss: 10.1064\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6360 - loss: 11.8678 - val_accuracy: 0.6400 - val_loss: 10.3113\n",
      "Epoch 3/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 203ms/step - accuracy: 0.7372 - loss: 7.2333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.7422 - loss: 6.0690 - val_accuracy: 0.7600 - val_loss: 3.1348\n",
      "Epoch 4/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 210ms/step - accuracy: 0.8276 - loss: 2.8098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.8345 - loss: 2.5876 - val_accuracy: 0.8400 - val_loss: 2.2876\n",
      "Epoch 5/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 221ms/step - accuracy: 0.8229 - loss: 2.4911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8389 - loss: 1.8259 - val_accuracy: 0.8400 - val_loss: 1.7987\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8298 - loss: 1.4657 - val_accuracy: 0.7600 - val_loss: 2.5699\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8617 - loss: 1.0718 - val_accuracy: 0.6400 - val_loss: 4.9729\n",
      "Epoch 8/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 207ms/step - accuracy: 0.7473 - loss: 2.3215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.7755 - loss: 2.2158 - val_accuracy: 0.7400 - val_loss: 2.4623\n",
      "Epoch 9/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 204ms/step - accuracy: 0.8952 - loss: 0.6069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.8927 - loss: 0.7116 - val_accuracy: 0.8000 - val_loss: 2.3089\n",
      "Epoch 10/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 206ms/step - accuracy: 0.9181 - loss: 0.5731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9456 - loss: 0.3313 - val_accuracy: 0.8000 - val_loss: 1.9979\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9175 - loss: 0.3300 - val_accuracy: 0.7400 - val_loss: 2.4011\n",
      "Epoch 12/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - accuracy: 0.8370 - loss: 0.7842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8398 - loss: 0.7832 - val_accuracy: 0.8200 - val_loss: 1.6993\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9579 - loss: 0.1393 - val_accuracy: 0.7400 - val_loss: 2.2051\n",
      "Epoch 14/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 204ms/step - accuracy: 0.9551 - loss: 0.1612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9667 - loss: 0.1253 - val_accuracy: 0.7800 - val_loss: 2.1315\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9753 - loss: 0.0889 - val_accuracy: 0.7600 - val_loss: 3.0142\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9695 - loss: 0.1021 - val_accuracy: 0.7400 - val_loss: 3.2209\n",
      "Epoch 17/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 201ms/step - accuracy: 0.9458 - loss: 0.1590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9591 - loss: 0.1411 - val_accuracy: 0.8000 - val_loss: 2.2859\n",
      "Epoch 18/20\n",
      "\u001b[1m 13/200\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 220ms/step - accuracy: 0.9967 - loss: 0.0079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.8000 - val_loss: 1.8526\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8000 - val_loss: 2.0431\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9258 - loss: 0.5866 - val_accuracy: 0.5800 - val_loss: 9.0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 11:44:33 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2024/09/13 11:44:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, \n",
    "          steps_per_epoch = train_generator.samples // 2,\n",
    "          epochs=20, \n",
    "         validation_data=validation_generator,\n",
    "         validation_steps=validation_generator.samples // 2,\n",
    "         verbose=1)\n",
    "\n",
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5012 - loss: 10.7679\n",
      "Validation Accuracy: 58.00%\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.6154 - loss: 4.4532\n",
      "Train Accuracy: 63.50%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "train_loss, train_accuracy = model.evaluate(train_generator)\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Prediction using trained model\n",
    "print(type(test_x))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step\n",
      "[[7.6082373e-16 1.0000000e+00]\n",
      " [2.9676914e-14 1.0000000e+00]\n",
      " [1.4644294e-23 1.0000000e+00]\n",
      " [5.4464674e-01 4.5535326e-01]\n",
      " [7.7723709e-15 1.0000000e+00]\n",
      " [1.8851539e-07 9.9999976e-01]\n",
      " [4.6412831e-18 1.0000000e+00]\n",
      " [2.8825079e-11 1.0000000e+00]\n",
      " [2.6827872e-12 1.0000000e+00]\n",
      " [5.2743114e-04 9.9947256e-01]\n",
      " [1.7912515e-11 1.0000000e+00]\n",
      " [3.1518654e-04 9.9968481e-01]\n",
      " [1.7154188e-16 1.0000000e+00]\n",
      " [4.4323945e-10 1.0000000e+00]\n",
      " [3.7178867e-09 1.0000000e+00]\n",
      " [6.3391238e-01 3.6608765e-01]\n",
      " [2.9567578e-11 1.0000000e+00]\n",
      " [5.0978433e-17 1.0000000e+00]\n",
      " [5.5986398e-01 4.4013599e-01]\n",
      " [5.1800029e-08 1.0000000e+00]\n",
      " [6.9963824e-14 1.0000000e+00]\n",
      " [1.5862004e-16 1.0000000e+00]\n",
      " [6.9757589e-13 1.0000000e+00]\n",
      " [1.5741737e-25 1.0000000e+00]\n",
      " [1.9966062e-06 9.9999797e-01]\n",
      " [1.3172152e-16 1.0000000e+00]\n",
      " [8.2751448e-19 1.0000000e+00]\n",
      " [3.2821200e-12 1.0000000e+00]\n",
      " [2.6534493e-12 1.0000000e+00]\n",
      " [6.8322395e-25 1.0000000e+00]\n",
      " [1.2663476e-24 1.0000000e+00]\n",
      " [1.0835490e-12 1.0000000e+00]\n",
      " [1.8728872e-05 9.9998128e-01]\n",
      " [1.6843934e-04 9.9983156e-01]\n",
      " [1.8826219e-08 1.0000000e+00]\n",
      " [1.4037754e-14 1.0000000e+00]\n",
      " [1.9009257e-03 9.9809915e-01]\n",
      " [2.0735808e-04 9.9979264e-01]\n",
      " [3.5065046e-15 1.0000000e+00]\n",
      " [9.8545700e-01 1.4543000e-02]\n",
      " [9.2176137e-13 1.0000000e+00]\n",
      " [3.5693978e-21 1.0000000e+00]\n",
      " [3.6695793e-20 1.0000000e+00]\n",
      " [4.5363456e-14 1.0000000e+00]\n",
      " [1.5554483e-25 1.0000000e+00]\n",
      " [1.0374380e-12 1.0000000e+00]\n",
      " [1.5193109e-11 1.0000000e+00]\n",
      " [2.7950576e-12 1.0000000e+00]\n",
      " [9.7716707e-01 2.2832962e-02]\n",
      " [1.4380755e-12 1.0000000e+00]]\n",
      "Predicted classes: [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Batch Prediction\n",
    "predictions = model.predict(test_x)\n",
    "\n",
    "print(predictions)\n",
    "# If you want to get the predicted class for each image\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print predicted classes\n",
    "print(\"Predicted classes:\", predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "[[6.035186e-13 1.000000e+00]]\n",
      "Predicted class: [1]\n"
     ]
    }
   ],
   "source": [
    "#Single image Prediction\n",
    "pred_path = '20.jpg'\n",
    "img = image.load_img(pred_path, target_size=(224,224))\n",
    "\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0 \n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions) \n",
    "\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "model_signature = infer_signature(test_x, model.predict(test_x))\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "input_data_path = 'v_data'\n",
    "exp_timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "exp_name = \"custom_ds\" + exp_timestamp\n",
    "print(exp_name)\n",
    "\n",
    "run_timestamp = datetime.now().strftime(\"%Y%m%d--%H%M%S\")\n",
    "run_name = \"custom_ds_run\"+ run_timestamp\n",
    "print(run_name)\n",
    "\n",
    "#mlflow.tensorflow.autolog(log_every_epoch=2)\n",
    "\n",
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "        #mlflow.log_artifact(input_data_path, artifact_path=\"input_data\")\n",
    "        mlflow.log_param(\"batch_size\", 2)\n",
    "        #mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", 20)\n",
    "        mlflow.log_metric(\"train_loss\", train_loss)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "        \n",
    "        mlflow.tensorflow.log_model(model, \"custom_ds\", signature=model_signature,registered_model_name='custom_ds_model')\n",
    "mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
